{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepTC_net_image.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aachen6/deepTC/blob/master/colab/deepTC_net_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wk3zltbBVuNp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DeepTC - Post-binding Architecture\n",
        "\n",
        "The objective of *deepTC* can be found on [deepTC github page](https://github.com/aachen6/deepTC/) for new readers. Now, we have the best track and satellite image dataset of the historical TCs ready from the first two notebooks. This notebook will cover architecture of *deepTC*, which is based on *pytorch*. To explore different deep neural network architectures efficiently,  *deepTC* features post-binding deep neutral network architecture from a configuration file without revising a single line of the code. \n",
        "\n",
        "1. Data Preprocess\n",
        "   - 1.1 [Satellite images and tracks of TCs](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_images_tracks_sync.ipynb)\n",
        "\n",
        "   - 1.2 [Statistics of satellite images and tracks](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_images_tracks_stats.ipynb)\n",
        "\n",
        "2. Model for TC Image\n",
        "   - **2.1 [Post-binding architecture of TC image](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_net_image.ipynb)**\n",
        "\n",
        "   - 2.2 [CNN model for intensity classification](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_classification_cnn5.ipynb)\n",
        "\n",
        "   - 2.3 [Resnet model for intensity classification](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_classification_resnet.ipynb)\n",
        "\n",
        "   - 2.4 [Resnet model for TC intensity estimation](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_intensity_resnet.ipynb)\n",
        "\n",
        "3. Generversial Model for TC images\n",
        "   - 3.1 [DCGAN model for deepTC](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_dcgan.ipynb)\n",
        "\n",
        "4. Model for TC Track\n",
        "   - 4.1 [Post-binding architecture of TC Track](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_net_track.ipynb)\n",
        "    \n",
        "   - 4.2 [LSTM model for TC track prediction](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_track_lstm.ipynb)\n",
        " \n",
        "   - 4.3 [LSTM-CNN model for TC track prediction](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_track_lstmcnn.ipynb)\n",
        "\n",
        "\n",
        "Let's start with importing the necessary python modules, particularly installing pytorch with GPU support on Google Colab."
      ]
    },
    {
      "metadata": {
        "id": "DIhxSG4TKW8e",
        "colab_type": "code",
        "outputId": "6427664d-a25e-4934-c98d-e37955205705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "# basics\n",
        "import os\n",
        "import yaml\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "# intall an early verison of pillow, as the latest pillow cause an error \n",
        "# when loading images from zip file\n",
        "!pip install pillow==4.1.1\n",
        "\n",
        "# handling the images\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# install and load pytorch\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.enabled = False  # it seems that cudnn doesn't work"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iswBDxJRL8JF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Post-Binding Deep Neutral Network\n",
        "\n",
        "It's beneficial to test different architectures of deep netural network. To make the process more efficient, we decouple the model construction from the code by post-binding the deep neutral network from a configuration file. A *YAML* configuration file is used to define the architecture of the deep netural network. Two classes are created to construct the deep neutral network based on the *YAML* configuration file, i.e. a static class mapping method string names to pytorch methods or class instances and a pytorch module subclass to generate the model instance. Currently, sequential model with an extension to have residual block/net is implemented. It is straightforward to extend the idea to include more complex deep neutral network architectures. \n",
        "\n",
        "The first class *PyTorchCall* is simply a static class that maps pytorch methods based on their string names with the corresponding arguements. Only the necessary methods for the current application are included at this moment. The implementation is very straightforward utilizing *python getattr* method. \n",
        "\n",
        "~~~python\n",
        "class PyTorchCall:\n",
        "     def map_torch_call(func_str):\n",
        "          return getattr(PytorchCall, '_' + func_str)\n",
        "     # any pytorch calls to be added below\n",
        "~~~"
      ]
    },
    {
      "metadata": {
        "id": "Z4iLs9RIMWOm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PyTorchCall:\n",
        "\n",
        "    # will update to unroll function variables using **kwarg\n",
        "  \n",
        "    @staticmethod\n",
        "    def map_torch_call(func_str): return getattr(PyTorchCall, '_' + func_str)\n",
        "\n",
        "    # pytorch nn calls\n",
        "    @staticmethod \n",
        "    def _linear(args): return nn.Linear(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _dropout(args): return nn.Dropout(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _conv2d(args):\n",
        "        return nn.Conv2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _deconv2d(args):\n",
        "        return nn.ConvTranspose2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _upsample(args):\n",
        "        return nn.Upsample(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _batchnorm2d(args):\n",
        "        return nn.BatchNorm2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod     \n",
        "    def _avgpool2d(args):\n",
        "        return nn.AvgPool2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod    \n",
        "    def _maxpool2d(args):\n",
        "        return nn.MaxPool2d(*args['args'], **args['kwargs'])\n",
        "\n",
        "    @staticmethod\n",
        "    def _relu(args):\n",
        "        return nn.ReLU(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _tanh(args):\n",
        "        return nn.Tanh(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _sigmoid(args):\n",
        "        return nn.Sigmoid(*args['args'], **args['kwargs'])\n",
        "    @staticmethod \n",
        "    def _leakyrelu(args):\n",
        "        return nn.LeakyReLU(*args['args'], **args['kwargs'])\n",
        "\n",
        "    # pytorch functional\n",
        "    #@staticmethod\n",
        "    #def _relu(args): return F.relu\n",
        "    @staticmethod \n",
        "    def _batchnorm(args): return F.batch_norm\n",
        "    @staticmethod\n",
        "    def _softmax(args): return F.softmax\n",
        "\n",
        "    @staticmethod\n",
        "    def _view1d(args): return  \n",
        "    @staticmethod\n",
        "    def _view2d(args): return\n",
        "      \n",
        "    # pytorch loss\n",
        "    @staticmethod\n",
        "    def _mseloss(): return nn.MSELoss() \n",
        "    @staticmethod\n",
        "    def _bceloss(): return nn.BCELoss()\n",
        "    @staticmethod\n",
        "    def _crossentropy(): return nn.CrossEntropyLoss() \n",
        "\t\t\n",
        "    # pytorch optimiter\n",
        "    @staticmethod\n",
        "    def _adam(): return optim.Adam\n",
        "\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkfdlpxZZkBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The second class *YML2Model* inherits pytoch *nn.Module* that is designed to generate pytorch model instance based on the *YAML* configuration file. The configuration file defines each layer of deep neutral network according to pytorch *nn.Module*. An example of two-layer convolution network is shown below,\n",
        "\n",
        "~~~yaml\n",
        "model: \n",
        " - cnn2\n",
        "cnn2:\n",
        "  - layer1-sequential: # groupd into sequential but can be expanded out into each layer\n",
        "    - conv2d:\n",
        "        args: [1, 32, 3]\n",
        "        kwargs: [padding: 1, stride: 1]\n",
        "    - maxpool2d:\n",
        "        args: [2]\n",
        "        kwargs: [padding: 0, stride: 2]\n",
        "    - relue:\n",
        "        args: []\n",
        "        kwargs: {}\n",
        "  - layer2-sequential:\n",
        "    - conv2d:\n",
        "        args: [32, 32, 3]\n",
        "        kwargs: [padding: 1, stride: 1]\n",
        "    - maxpool2d:\n",
        "        args: [2]\n",
        "        kwargs: [padding: 0, stride: 2]\n",
        "    - relue:\n",
        "        args: []\n",
        "        kwargs: {}        \n",
        "  - layer3-view:\n",
        "      args: []\n",
        "      kwargs: {}\n",
        "  - layer4-linear:\n",
        "      args: [8192, 10]\n",
        "      kwargs: {}\n",
        "~~~\n",
        "\n",
        "The pytorch module subclass should inherit *nn.Mudule* and define the following methods:\n",
        "\n",
        "~~~python\n",
        "__init__ : # define layer as class variable\n",
        "__forward__: # forward loop for the network \n",
        "~~~\n",
        "The *init* method construct each layer as its class variable, which are eventually used in the forward method. *View* method is included as a layer which is handled seperately. Alternatively, this method can be wrapped into a separate pytorch *nn.Module* subclass. Since the pytorch *nn.Module* is sequential, a residual block class *YML2Resblock* that inherits pytorch *nn.Module* is also defined to enable residual network. It is straightforward to extend the idea to generate more complex deep neutral network architectures. "
      ]
    },
    {
      "metadata": {
        "id": "F0LxYEZ2D8B0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class YML2Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, config, model_name):\n",
        "      \n",
        "        super(YML2Model, self).__init__()\n",
        "      \n",
        "        self.layers = []\n",
        "        cfg_model = config[model_name]\n",
        "        for lyr_cfg in cfg_model:\n",
        "            # get current layer name, typc, and arguments\n",
        "            lyr_key = list(lyr_cfg.keys())[0]\n",
        "            [lyr_name, lyr_type] = lyr_key.split('-')\n",
        "            lyr_args = lyr_cfg[lyr_key]\n",
        "            \n",
        "            # residual block\n",
        "            if lyr_type == 'resblock':     # resblock\n",
        "                lyr_module = YML2Resblock(config['resblocks'][lyr_args])\n",
        "            \n",
        "            # sequential layer\n",
        "            elif lyr_type == 'sequential': # layer in sequential\n",
        "                modules = []\n",
        "                for row in lyr_args:\n",
        "                    r_func = list(row.keys())[0]\n",
        "                    r_args = row[r_func]                  \n",
        "                    r_module = PyTorchCall.map_torch_call(r_func)(r_args)\n",
        "                    modules.append(r_module)\n",
        "                    if r_func == 'lstm': \n",
        "                        self.hidden_dim = r_args['args'][1]  \n",
        "                        self.num_layers = r_args['kwargs']['num_layers']\n",
        "                        #self.init_hidden(1, r_func) # need to take care of bidirection\n",
        "                lyr_module = nn.Sequential(*modules)\n",
        "                               \n",
        "            else: # individual nn.module\n",
        "                lyr_module = PyTorchCall.map_torch_call(lyr_type)(lyr_args) \n",
        "               \n",
        "            # register layer to the class\n",
        "            setattr(self, lyr_name, lyr_module)\n",
        "            self.layers.append([lyr_type, lyr_args, getattr(self, lyr_name)])\n",
        "            \n",
        "            \n",
        "    def forward(self, x):\n",
        " \n",
        "        # implementation of Module forward method\n",
        "        for lyr_type, ly_arg, lyr_module in self.layers:\n",
        "            # print (lyr_module)\n",
        "            if lyr_type == 'view1d': \n",
        "                n = int(np.prod(x.size()[1:]))\n",
        "                x = x.view(-1, n)\n",
        "            elif lyr_type == 'view2d':\n",
        "                kwargs = ly_arg['kwargs']\n",
        "                x = x.view(x.size()[0], kwargs['channel'], kwargs['size'], kwargs['size'])\n",
        "            else:  # nn.module instance\n",
        "                x = lyr_module(x)\n",
        "                \n",
        "        return x     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "baK0SNIUfIj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the implementation of residual block class, which is essentialy similar to *YML2Network* class, execpt that it allows non-sequential link of the pytorch *nn.Module*. The details will be covered later in the implementation of the residual network."
      ]
    },
    {
      "metadata": {
        "id": "1LfToyvpzwaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class YML2Resblock(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, cfg_block):\n",
        "      \n",
        "        super(YML2Resblock, self).__init__()\n",
        "        \n",
        "        self.layers = []\n",
        "        for cfg_lyr in cfg_block:\n",
        "            # get current layer name, typc, and arguments\n",
        "            lyr_key = list(cfg_lyr.keys())[0]\n",
        "            [lyr_name, lyr_type] = lyr_key.split('-')\n",
        "            lyr_args = cfg_lyr[lyr_key]\n",
        "            if lyr_type == 'residual':\n",
        "                row = lyr_args[0]\n",
        "                r_func = list(row.keys())[0]\n",
        "                r_args = row[r_func]\n",
        "                lyr_module = PyTorchCall.map_torch_call(r_func)(r_args)\n",
        "\n",
        "            # sequential layer\n",
        "            elif lyr_type == 'sequential':  # individaul layer\n",
        "                modules = []\n",
        "                for row in lyr_args:\n",
        "                    r_func = list(row.keys())[0]\n",
        "                    r_args = row[r_func]                  \n",
        "                    r_module = PyTorchCall.map_torch_call(r_func)(r_args)\n",
        "                    modules.append(r_module)\n",
        "                lyr_module = nn.Sequential(*modules)\n",
        "                              \n",
        "            else: #  torch module\n",
        "                lyr_module = PyTorchCall.map_torch_call(lyr_type)(lyr_args) \n",
        "               \n",
        "            # register layer to the class\n",
        "            setattr(self, lyr_name, lyr_module)\n",
        "            self.layers.append([lyr_type, getattr(self, lyr_name)])\n",
        "            \n",
        "            \n",
        "    def forward(self, x):\n",
        "      \n",
        "        residual = x\n",
        "        \n",
        "        for i, (lyr_type, lyr_module) in enumerate(self.layers):\n",
        "            if lyr_type == 'residual':  \n",
        "                residual = lyr_module(x)\n",
        "                break\n",
        "                \n",
        "            if i==0: \n",
        "                out = lyr_module(x)\n",
        "            else:  # nn.module instance\n",
        "                out = lyr_module(out)\n",
        "                       \n",
        "        out += residual\n",
        "        \n",
        "        if self.layers[-1][0]=='relu':\n",
        "            out = self.layers[-1][1](out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8Rh-OBsMPrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Storm Dataset Class\n",
        "\n",
        "A lot of effort in solving any machine learning problem goes in to preparing the data. To make the process easy, this class inherits pytorch *Dataset* class and handles data preparation before feeding into the training. According to pytorch document, the custom dataset class should inherit *Dataset* and override the following methods:\n",
        "\n",
        "~~~python\n",
        "__len__ : # so that len(dataset) returns the size of the dataset.\n",
        "__getitem__: # to support the indexing such that dataset can be used to get ith sample\n",
        "~~~\n",
        "\n",
        "The *getitem* method returns training input and target, and the index for data is also returned which can be used later during the post-processing, e.g. to idenfity mis-classified images from confusion matrix. A data split method is also implemented to split the data into training, validation, and test set. As shown earlier, the number of samples for each class are not well-balanced, therefore, label-aware can be enabled in the split method so that the ratio of sample size of each class is preserved within training, validation, and testing sets. \n"
      ]
    },
    {
      "metadata": {
        "id": "SO7xuF33MW_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "class ImageDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, config, transform=None, cats=None, hotstart=False):\n",
        "        \n",
        "        self.model_object = config['model_object']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.num_workers = config['num_workers']\n",
        "        \n",
        "        # read input files\n",
        "        f_storm_msg = config['f_storm_msg']\n",
        "        self.pd_storm = pd.read_msgpack(f_storm_msg)\n",
        "        \n",
        "        # load image archive\n",
        "        f_image_zip = config['f_image_zip']\n",
        "        self.img_archv = ZipFile(f_image_zip, 'r')\n",
        "        \n",
        "        # define transformation    \n",
        "        self.transform = transform\n",
        "        \n",
        "        # train valid test split\n",
        "        f_data_yml = config['f_data_yml']\n",
        "        if hotstart: # read from file\n",
        "            with open(f_data_yml, 'rb') as fp: \n",
        "                data = yaml.load(fp)\n",
        "                self.data_indices = data['indices']\n",
        "                if 'class' in self.model_object:\n",
        "                    self.one_hot_key = data['one_hot_key'] \n",
        "                    self.one_hot_rev = data['one_hot_rev']  \n",
        "        else: # create a new split\n",
        "            if 'class' in self.model_object:\n",
        "                # define one hot key map\n",
        "                self.one_hot_key = {}\n",
        "                self.one_hot_rev = {}\n",
        "                if cats is None:\n",
        "                    cats = set(self.pd_storm[b'cat'].tolist())\n",
        "                    cats = sorted(list(cats))\n",
        "                for i, cat in enumerate(sorted(cats)):\n",
        "                    self.one_hot_key[cat] = i\n",
        "                    self.one_hot_rev[i] = cat\n",
        "            \n",
        "            # train validation split\n",
        "            self.data_indices = self.train_valid_test(config)\n",
        "\n",
        "            data = {} # save dataset\n",
        "            data['indices'] = self.data_indices  \n",
        "            if 'class' in self.model_object:\n",
        "                data['one_hot_key'] = self.one_hot_key\n",
        "                data['one_hot_rev'] = self.one_hot_rev            \n",
        "                      \n",
        "            with open(f_data_yml, 'w') as fp: \n",
        "                yaml.dump(data, fp)\n",
        "            \n",
        "        # summary of dataset\n",
        "        valid_pct = 1.- config['valid_pct']\n",
        "        test_pct = 1. - config['test_pct']\n",
        "        n_train = len(self.data_indices['train'])\n",
        "        n_valid = len(self.data_indices['valid'])\n",
        "        n_test = len(self.data_indices['test'])\n",
        "        batch = self.batch_size\n",
        "        \n",
        "        divider = '-' * 36\n",
        "        header  = '{:<10s}{:>10s}{:>10s}{:>10s}'\n",
        "        record1 = '{:<10s}{:>10.2f}{:>10.2f}{:>10.2f}'\n",
        "        record2 = '{:<10s}{:>10d}{:>10d}{:>10d}'\n",
        "\n",
        "        print (divider)\n",
        "        print ('summary of dataset')\n",
        "        print (divider)\n",
        "        print (header.format(' ', 'train', 'valid', 'test')) \n",
        "        print (record1.format('percent', test_pct*valid_pct, test_pct*(1-valid_pct), 1-test_pct))\n",
        "        print (record2.format('size', n_train, n_valid, n_test))\n",
        "        print (record2.format('batch', int(n_train/batch), int(n_valid/batch), int(n_test/batch)))\n",
        "\n",
        "        return            \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.pd_storm[0].count()\n",
        "            \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        row = self.pd_storm.iloc[idx]\n",
        "        cat = row[b'cat']\n",
        "\n",
        "        if 'class' in self.model_object:\n",
        "            target = self.one_hot_key[cat]   # no need to create one hot for pytorch\n",
        "        else:\n",
        "            target = [row[b'wind'], row[b'pres']]\n",
        "                \n",
        "        image = row[b'image'].decode('utf-8')\n",
        "        temp = image.split('.')[0].split('_')\n",
        "        f_image = temp[0] + '_' + temp[1] + '.jpg'\n",
        "        \n",
        "        sample = Image.open(self.img_archv.open(f_image))\n",
        "        if self.transform is not None: \n",
        "            sample = self.transform(sample)\n",
        "                \n",
        "        return idx, sample, target \n",
        "\t\t\n",
        "    \n",
        "    def random_split(self, indices, pct, label_aware=True, shuffle=True, seed=64):\n",
        "      \n",
        "        # creating data indices for two splits:\n",
        "        indices_1 = []  # first half of the indices\n",
        "        indices_2 = []  # second half of the indices\n",
        "        cats = set(self.pd_storm[b'cat'].tolist()) if label_aware else ['all']\n",
        "        pd_sub = self.pd_storm.iloc[indices]\n",
        "        for cat in cats:\n",
        "            sub_indices = pd_sub[pd_sub[b'cat']==cat].index.tolist() if label_aware else indices\n",
        "            if shuffle: np.random.seed(seed)\n",
        "            np.random.shuffle(sub_indices)\n",
        "\n",
        "            isplit  = int(np.floor(len(sub_indices)*pct))            \n",
        "            indices_1 = indices_1 + sub_indices[:isplit]\n",
        "            indices_2 = indices_2 + sub_indices[isplit:]\n",
        "        \n",
        "        return indices_1, indices_2\n",
        "\n",
        "      \n",
        "    def train_valid_test(self, config):\n",
        "        \n",
        "        data_indices = {} \n",
        "        valid_pct = 1.- config['valid_pct']\n",
        "        test_pct = 1. - config['test_pct']\n",
        "        label_aware = config['label_aware']\n",
        "        shuffle = config['shuffle']\n",
        "        seed = config['seed']\n",
        "        \n",
        "        indices = self.pd_storm.index.tolist()\n",
        "        \n",
        "        if config['test_pct'] is None:\n",
        "            test_indices = None\n",
        "            train_indices, valid_indices = self.random_split(indices, valid_pct, label_aware, shuffle, seed)\n",
        "        else:\n",
        "            _indices, test_indices = self.random_split(indices, test_pct, label_aware, shuffle)\n",
        "            train_indices, valid_indices = self.random_split(_indices, valid_pct, label_aware, shuffle, seed) \n",
        "            \n",
        "        data_indices['train'] = train_indices\n",
        "        data_indices['valid'] = valid_indices\n",
        "        data_indices['test'] = test_indices\n",
        "            \n",
        "        return data_indices\n",
        "\n",
        "      \n",
        "    def load_data(self):\n",
        "      \n",
        "        data_split = {} \n",
        "        \n",
        "        batch_size = self.batch_size\n",
        "        num_workers = self.num_workers\n",
        "       \n",
        "        train_indices = self.data_indices['train']\n",
        "        valid_indices = self.data_indices['valid']\n",
        "        test_indices = self.data_indices['test']\n",
        "            \n",
        "        train_sampler = SubsetRandomSampler(train_indices)\n",
        "        valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "\n",
        "        data_split['train'] = DataLoader(self, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "        data_split['valid'] = DataLoader(self, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)        \n",
        "        \n",
        "        if test_indices is None:\n",
        "            data_split['test'] = None \n",
        "        else:\n",
        "            test_sampler = SubsetRandomSampler(test_indices)  \n",
        "            data_split['test'] = DataLoader(self, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)\n",
        "        \n",
        "        return data_split\n",
        "      \n",
        "     \n",
        "    def normalization_factor(self, sample_a, sample_b):\n",
        "      \n",
        "        (n_a, mean_a, std_a) = sample_a\n",
        "        (n_b, mean_b, std_b) = sample_b\n",
        "  \n",
        "        n_c = n_a + n_b\n",
        "        mean_c = n_a*mean_a + n_b*mean_b\n",
        "        mean_c = mean_c/n_c\n",
        "  \n",
        "        numerator = (n_a-1)*std_a**2. + (n_b-1)*std_b**2. + \\\n",
        "                    n_a*(mean_a-mean_c)**2. + n_b*(mean_b-mean_c)**2.\n",
        "  \n",
        "        denorminator = n_c - 1\n",
        "  \n",
        "        std_c = np.sqrt(numerator/denorminator)\n",
        "  \n",
        "        return np.array([n_c, mean_c, std_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsobgYV5RBbf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Image Trainer Class\n",
        "\n",
        "This is when things start to get interesting. The trainer class links everything togther and perform training to optimize the network based on loss objective. During initilization of the trainer instance,  parameters like number of epoch, batch size, loss funcation etc. are passed from the configuration file. Some state parameters are also initialized to document the training state for model assessment, such as training_batch_loss, training_batch_accuracy etc. The model net is passed to the trainer class, and the loss function and optimizer are initialized based on the configuration file. Finally, we simply have to loop over our data iterator, and feed the inputs to the network and optimize. \n",
        "~~~python\n",
        "for i_epoch in range(self.max_epochs):\n",
        "    for i_batch, (_, images, labels) in enumerate(data['train']): \n",
        "        self.optimizer.zero_grad()  # set the gradient to zero \n",
        "        predicts = self.model(images)  # make prediction\n",
        "        loss = self.criterion(predicts, labels)  # calculate loss \n",
        "        loss.backward() # backpropagation to get the weight update\n",
        "        self.optimizer.step() # update weight using the optimizer\n",
        "~~~\n",
        "During the training, we follow the approach similar to [this tutorial](https://github.com/GokuMohandas/practicalAI/blob/master/notebooks/11_Convolutional_Neural_N`etworks.ipynb) by Goku Mohandas to calculate the running epoch loss and accuracy. \n",
        "~~~python\n",
        "batch_accu = self.accuracy(predicts, labels)\n",
        "epoch_accu += (batch_accu - epoch_accu) / (i_batch + 1)\n",
        "~~~              \n",
        "Depending on the number of parameters, it may take a long time to run. It would be cost-efficient to detect early stopping if the proposed architecture does work well for the problem.  In order to check the process and performance of the training while it's running, two methods are implemented, i.e. a method to show progress bar for each epoch and a method for dynamic visualiation of batch and running epoch loss and accuracy. Those methods embed html in the notebook for dynamic refresh.\n",
        "\n",
        "~~~python\n",
        "def html_loss_plot(self, image):\n",
        "    return  HTML(\"<img src='{0}'/>\".format(image))\n",
        "  \n",
        "def html_progress(self, var, value, max=100):\n",
        "    return HTML(\"\"\"{var}: <progress value='{value}' max='{max}', style='width: 80%'>{value}\n",
        "                            </progress>\"\"\".format(var=var, value=value, max=max))\n",
        " ~~~\n",
        "During the training, the state parameters will be saved into a file for post-process and/or hotstart the training. The model dict state will be saved as well using *torch.save* method.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "V4Ep0RGLRCNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "\n",
        "class ImageTrainer(object):\n",
        "    def __init__(self, params, model, hotstart=False):\n",
        "        # CUDA for PyTorch\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
        "        if self.device!='cpu':\n",
        "            divider = '-' * 36\n",
        "            print(divider)\n",
        "            print('summary of GPU')\n",
        "            print(divider)\n",
        "            print(torch.cuda.get_device_name(0))\n",
        "            print('Memory Usage:')\n",
        "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "            print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "        else:\n",
        "            print('training with cpu')   \n",
        " \n",
        "        # model objective\n",
        "        self.model_object = params['model_object']\n",
        "\n",
        "        # hyper params\n",
        "        self.max_epochs = params['max_epochs']\n",
        "        self.batch_size = params['batch_size']\n",
        "        self.r_learning = params['r_learning']\n",
        "        self.loss_func  = params['loss_func']\n",
        "        self.optim_func = params['optimizer']\n",
        " \n",
        "        # path for output\n",
        "        self.f_state    = params['f_state_yml']\n",
        "        self.f_model    = params['f_model_pth']\n",
        "        self.f_test     = params['f_test_yml']\n",
        "        \n",
        "        # training state \n",
        "        self.state = {'stop_early':   False,\n",
        "                      'stop_criteria': 99.9,\n",
        "                      'stop_step':    0,\n",
        "                      'epoch_index':  0,\n",
        "                      'best_epoch':   -1,\n",
        "                      'best_accu' :   -1,\n",
        "                      'test_loss':    -1,\n",
        "                      'test_accu':    -1,\n",
        "                      'train_epoch_loss': [],\n",
        "                      'train_epoch_accu': [],\n",
        "                      'train_batch_loss': [],\n",
        "                      'train_batch_accu': [],\n",
        "                      'valid_epoch_loss': [],\n",
        "                      'valid_epoch_accu': [],\n",
        "                      'valid_batch_loss': [],\n",
        "                      'valid_batch_accu': []}\n",
        "\n",
        "        # model\n",
        "        self.model = model.to(self.device)\n",
        "        # loss\n",
        "        self.criterion = PyTorchCall.map_torch_call(self.loss_func)()\n",
        "        # optimizer\n",
        "        self.optimizer = PyTorchCall.map_torch_call(self.optim_func)()\n",
        "        self.optimizer = self.optimizer(model.parameters(), lr=self.r_learning)\n",
        "        \n",
        "        if hotstart: # hotstart \n",
        "            model_state = torch.load(params['f_model_pth'])\n",
        "            self.model.load_state_dict(model_state['model_state_dict'])\n",
        "            for key, value in self.state.items():\n",
        "                self.state[key] = model_state[key]\n",
        "    \n",
        "\n",
        "    def train_loop(self, data):\n",
        "        \n",
        "        divider = '-' * 36\n",
        "        header  = '{:<10s}{:>10s}{:>10s}'\n",
        "        record  = '{:<10s}{:>10.3f}{:>10.3f}'\n",
        "        print (divider)\n",
        "        print ('training')\n",
        "        print (divider)\n",
        "        \n",
        "        loss_plot = display(self.html_loss_plot('PLOT'), display_id=True)\n",
        "        \n",
        "        # loop over epochs\n",
        "        for i_epoch in range(self.max_epochs):\n",
        "            \n",
        "            self.state['epoch_index'] = i_epoch\n",
        "            \n",
        "            # training\n",
        "            epoch_loss = 0.\n",
        "            epoch_accu = 0.\n",
        "            self.model.train()\n",
        "            bar_train = display(self.html_progress('Train', 0, 100), display_id=True)\n",
        "            for i_batch, (_, inputs, targets) in enumerate(data['train']):\n",
        "\n",
        "                # transfer to GPU\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                \n",
        "                # model computations\n",
        "                self.optimizer.zero_grad()\n",
        "                predicts = self.model(inputs)\n",
        " \n",
        "                loss = self.criterion(predicts, targets)\n",
        "                batch_loss = loss.item()\n",
        "                epoch_loss += (batch_loss - epoch_loss) / (i_batch + 1)\n",
        "                \n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                batch_accu = self.accuracy(predicts, targets)\n",
        "                epoch_accu += (batch_accu - epoch_accu) / (i_batch + 1)\n",
        "                \n",
        "                self.state['train_batch_loss'].append(batch_loss)\n",
        "                self.state['train_batch_accu'].append(batch_accu)\n",
        "\n",
        "                pct_done = (i_batch+1)/len(data['train'])*100\n",
        "                bar_train.update(self.html_progress('Train', pct_done, 100))\n",
        "\n",
        "            self.state['train_epoch_loss'].append(epoch_loss)\n",
        "            self.state['train_epoch_accu'].append(epoch_accu)\n",
        "  \n",
        "            # validation\n",
        "            epoch_loss = 0.\n",
        "            epoch_accu = 0.\n",
        "            self.model.eval()\n",
        "            bar_valid = display(self.html_progress('Valid', 0, 100), display_id=True)\n",
        "            for i_batch, (_, inputs, targets) in enumerate(data['valid']):\n",
        "                # transfer to GPU\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                \n",
        "                # model computations\n",
        "                self.optimizer.zero_grad()\n",
        "                predicts = self.model(inputs)\n",
        " \n",
        "                loss = self.criterion(predicts, targets)\n",
        "                batch_loss = loss.item()\n",
        "                epoch_loss += (batch_loss - epoch_loss) / (i_batch + 1)\n",
        "                \n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                batch_accu = self.accuracy(predicts, targets)\n",
        "                epoch_accu += (batch_accu - epoch_accu) / (i_batch + 1)\n",
        "                \n",
        "                self.state['valid_batch_loss'].append(batch_loss)\n",
        "                self.state['valid_batch_accu'].append(batch_accu)\n",
        "                \n",
        "                pct_done = (i_batch+1)/len(data['valid'])*100\n",
        "                bar_valid.update(self.html_progress('Valid', pct_done, 100))                \n",
        "                \n",
        "            self.state['valid_epoch_loss'].append(epoch_loss)\n",
        "            self.state['valid_epoch_accu'].append(epoch_accu)\n",
        "            \n",
        "            # epoch summary\n",
        "            if i_epoch%1==0:\n",
        "                print (divider)\n",
        "                print ('summary of epoch:', i_epoch)\n",
        "                print (divider)\n",
        "                print (header.format(' ', 'loss', 'accurary')) \n",
        "                print (record.format('train', self.state['train_epoch_loss'][-1], self.state['train_epoch_accu'][-1]))\n",
        "                print (record.format('valid', self.state['valid_epoch_loss'][-1], self.state['valid_epoch_accu'][-1]))\n",
        "                uri = self.update_loss_plot()\n",
        "                loss_plot.update(self.html_loss_plot(uri))\n",
        "                print (' ')\n",
        "            \n",
        "            self.update_save_state()\n",
        "            if self.state['stop_early']: break\n",
        "             \n",
        "        \n",
        "    def test_loop(self, data, apply_softmax=True):\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i_batch, (idxs, images, labels) in enumerate(data['test']):\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                predicts = self.model(images)\n",
        "                if apply_softmax:\n",
        "                    #print (np.array(predicts.data)[0])\n",
        "                    predicts  = F.softmax(predicts, 1) \n",
        "                    #print (np.array(predicts.data)[0])\n",
        "                    #break\n",
        "\n",
        "                _, predicted = torch.max(predicts.data, 1)\n",
        "            \n",
        "                if i_batch==0: \n",
        "                    test_idxs = idxs.data\n",
        "                    test_labels = labels.data\n",
        "                    test_predicts = predicted.data\n",
        "                else:\n",
        "                    test_idxs = torch.cat((test_idxs, idxs.data))\n",
        "                    test_labels = torch.cat((test_labels, labels.data))\n",
        "                    test_predicts = torch.cat((test_predicts, predicted.data))\n",
        "            \n",
        "                total += labels.size(0)\n",
        "                correct += (predicted==labels).sum()\n",
        "            \n",
        "        test_idxs = test_idxs.cpu().detach().numpy()\n",
        "        test_labels = test_labels.cpu().detach().numpy()\n",
        "        test_predicts = test_predicts.cpu().detach().numpy()\n",
        "       \n",
        "        # test summary\n",
        "        divider = '-' * 36\n",
        "        print(divider)\n",
        "        print('summary of test')\n",
        "        print(divider)\n",
        "        print('{:<10s}{:>10s}{:>10s}'.format('', 'total', 'accuracy'))\n",
        "        print('{:<10s}{:>10d}{:>10.3f}'.format('test', total, 100. * correct / total))    \n",
        "        \n",
        "        # save test\n",
        "        test_results = {}\n",
        "        test_results['idxs'] = test_idxs\n",
        "        test_results['labels'] = test_labels\n",
        "        test_results['predicts'] = test_predicts\n",
        "        test_results['accuracy'] = float(100 * correct / total)\n",
        "        \n",
        "        with open(self.f_test, 'w') as fp:\n",
        "            yaml.dump(test_results, fp)\n",
        "            \n",
        "        return test_results\n",
        "      \n",
        "        \n",
        "    def accuracy(self, predicts, targets):\n",
        "      \n",
        "        if self.model_object=='classification': \n",
        "            _, predicts_indices = predicts.max(dim=1)\n",
        "            n_correct = torch.eq(predicts_indices, targets).sum().item()\n",
        "            return n_correct / len(predicts_indices) * 100\n",
        "        \n",
        "        if self.model_object=='regression':\n",
        "            _, predicts_indices = predicts.max(dim=1)\n",
        "            n_correct = torch.eq(predicts_indices, targets).sum().item()\n",
        "            return n_correct / len(predicts_indices) * 100\n",
        "          \n",
        "   \n",
        "    def html_loss_plot(self, image):\n",
        "        \n",
        "        h = HTML(\"<img src='{0}'/>\".format(image))\n",
        "    \n",
        "        return h\n",
        "\n",
        "    \n",
        "    def html_progress(self, var, value, max=100):\n",
        "      \n",
        "        h = HTML(\"\"\"{var}: <progress value='{value}' max='{max}', style='width: 80%'>{value}\n",
        "                           </progress>\"\"\".format(var=var, value=value, max=max))\n",
        "    \n",
        "        return h\n",
        "       \n",
        "      \n",
        "    def update_loss_plot(self):\n",
        "        \n",
        "        train_batch_loss = self.state['train_batch_loss']\n",
        "        train_batch_accu = self.state['train_batch_accu']\n",
        "        train_epoch_loss = self.state['train_epoch_loss']\n",
        "        train_epoch_accu = self.state['train_epoch_accu']\n",
        "\n",
        "        ntb = len(train_batch_loss)\n",
        "        nte = len(train_epoch_loss)\n",
        "        nnn = ntb/nte \n",
        "        xtb = np.arange(ntb)/nnn \n",
        "        xte = np.arange(nte) + 1\n",
        "\n",
        "        valid_batch_loss = self.state['valid_batch_loss']\n",
        "        valid_batch_accu = self.state['valid_batch_accu']\n",
        "        valid_epoch_loss = self.state['valid_epoch_loss']\n",
        "        valid_epoch_accu = self.state['valid_epoch_accu']\n",
        "\n",
        "        nvb = len(valid_batch_loss)\n",
        "        nve = len(valid_epoch_loss)\n",
        "        nnn = nvb/nve \n",
        "        xvb = np.arange(nvb)/nnn \n",
        "        xve = np.arange(nve) + 1\n",
        "\n",
        "        fig, axes = plt.subplots(2,2, figsize=(8,6))\n",
        "        axes[0,0].plot(xtb, train_batch_loss)\n",
        "        axes[0,0].plot(xte, train_epoch_loss)\n",
        "        axes[0,1].plot(xtb, train_batch_accu)\n",
        "        axes[0,1].plot(xte, train_epoch_accu)\n",
        "        axes[1,0].plot(xvb, valid_batch_loss)\n",
        "        axes[1,0].plot(xve, valid_epoch_loss)\n",
        "        axes[1,1].plot(xvb, valid_batch_accu)\n",
        "        axes[1,1].plot(xve, valid_epoch_accu)\n",
        "\n",
        "        bio = io.BytesIO()\n",
        "        fig.savefig(bio, format='png')\n",
        "        bio.seek(0)\n",
        "        uri = 'data:image/png;base64,' + base64.encodebytes(bio.getvalue()).decode()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "        return uri\n",
        "      \n",
        "      \n",
        "    def update_save_state(self):\n",
        "        \n",
        "        # save state\n",
        "        with open(self.f_state, 'w') as fp:\n",
        "            yaml.dump(self.state, fp)\n",
        "            \n",
        "        # save model\n",
        "        if self.state['epoch_index']==0:\n",
        "            self.state['best_accu'] = 0 \n",
        "            self.state['best_epoch'] = self.state['epoch_index']\n",
        "\n",
        "        cur_accu = self.state['valid_epoch_accu'][-1]\n",
        "        if self.state['best_accu']<cur_accu:\n",
        "            self.state['best_accu'] = cur_accu\n",
        "            self.state['best_epoch'] = self.state['epoch_index']\n",
        "            if cur_accu>self.state['stop_criteria']: self.state['stop_early'] = True\n",
        "            # save the model\n",
        "            state_cp = deepcopy(self.state)\n",
        "            state_cp['model_state_dict'] = self.model.state_dict()\n",
        "            state_cp['optim_state_dict'] = self.optimizer.state_dict()\n",
        "            torch.save(state_cp, self.f_model)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsPcSZqn_jax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Storm Inference Class\n",
        "\n",
        "Once the model is trained and optimized, this class will initiate the model based on the configuration file and state dict file and predict for new samples, which is straightforward."
      ]
    },
    {
      "metadata": {
        "id": "Tdy9De-G_j8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ImageInference(object):\n",
        "  \n",
        "    def __init__(self, config, model_name):\n",
        "        # CUDA for PyTorch\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
        " \n",
        "        # Model\n",
        "        model = YML2Model(config, model_name)\n",
        "        model_state = torch.load(config['params']['f_model_pth'])\n",
        "        model.load_state_dict(model_state['model_state_dict'])\n",
        "        self.model = model.to(self.device)\n",
        "        \n",
        "    def inference(self, imgs, apply_softmax=True):\n",
        "     \n",
        "        #data = torch.zeros([64, 1, 256, 256])\n",
        "        #for i, im in enumerate(imgs): # assume less than batch size for now\n",
        "        #    data[i] = im\n",
        "                      \n",
        "        self.model.eval() \n",
        "        with torch.no_grad():\n",
        "            imgs = imgs.to(self.device)  \n",
        "            predicts = self.model(imgs)\n",
        "            if apply_softmax:\n",
        "                predicts = F.softmax(predicts, 1)\n",
        "        \n",
        "        return predicts.cpu().detach().numpy() \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nP3h3l7iPZQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Inplace Test of CNN/Resnet"
      ]
    },
    {
      "metadata": {
        "id": "Ooeys3g1UsWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In place test code block to be commented out \n",
        "\n",
        "'''\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "work_dir = r'/content/drive/My Drive/Colab Notebooks/deepTC'\n",
        "p_data  = work_dir + os.sep + 'data/AL'\n",
        "p_image = work_dir + os.sep + 'image/AL'\n",
        "p_model = work_dir + os.sep + 'model/tc_cnn5'\n",
        "\n",
        "# load configuration file\n",
        "f_config = p_model + os.sep + 'config_cnn5.yaml'\n",
        "with open(f_config, 'r') as fp: config = yaml.load(fp)\n",
        "  \n",
        "# contruct the model\n",
        "storm_cnn = YML2Model(config, 'cnn5')\n",
        "\n",
        "# update path for config\n",
        "config_params = config['params']\n",
        "config_params['f_image_zip'] = p_image + os.sep + config_params['f_image_zip']\n",
        "config_params['f_storm_msg'] = p_data  + os.sep + config_params['f_storm_msg']\n",
        "config_params['f_data_yml']  = p_model + os.sep + config_params['f_data_yml']\n",
        "config_params['f_state_yml'] = p_model + os.sep + config_params['f_state_yml']\n",
        "config_params['f_model_pth'] = p_model + os.sep + config_params['f_model_pth']\n",
        "config_params['f_test_yml']  = p_model + os.sep + config_params['f_test_yml']\n",
        "\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.456,), (0.222,))])\n",
        "\n",
        "# dataset\n",
        "storm_data = ImageDataSet(config_params, image_transforms, hotstart=False)\n",
        "data_split = storm_data.load_data()\n",
        "\n",
        "# model\n",
        "storm_train = ImageTrainer(config_params, storm_cnn, hotstart=False)\n",
        "\n",
        "# train & valid\n",
        "storm_train.train_loop(data_split)\n",
        "\n",
        "# test\n",
        "test_results = storm_train.test_loop(data_split)\n",
        "\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGd15dZDPhP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Inplace Test of GAN"
      ]
    },
    {
      "metadata": {
        "id": "HOKcjpn80O3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# In place test code block to be commented out \n",
        "\n",
        "'''\n",
        "%matplotlib inline\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "\n",
        "class ImageTrainerGAN(object):\n",
        "  \n",
        "    def __init__(self, params, g_model, d_model, hotstart=False):\n",
        "        # CUDA for PyTorch\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
        "        if self.device!='cpu':\n",
        "            divider = '-' * 36\n",
        "            print(divider)\n",
        "            print('summary of GPU')\n",
        "            print(divider)\n",
        "            print(torch.cuda.get_device_name(0))\n",
        "            print('Memory Usage:')\n",
        "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "            print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "        else:\n",
        "            print('training with cpu')  \n",
        "               \n",
        "        # model object\n",
        "        self.model_object = params['model_object']\n",
        " \n",
        "        # send model to device (CPU or GPU)\n",
        "        self.g_model = g_model.to(self.device)\n",
        "        self.d_model = d_model.to(self.device)\n",
        "    \n",
        "        # parameters\n",
        "        self.latent_dim = 128\n",
        "        self.f_state    = params['f_state_yml']\n",
        "        self.f_model    = params['f_model_pth']\n",
        "        self.f_test     = params['f_test_yml']\n",
        "        self.max_epochs = params['max_epochs']\n",
        "        self.batch_size = params['batch_size']\n",
        "        self.r_learning = params['r_learning']\n",
        "        self.loss_func  = params['loss_func']\n",
        "        self.g_optim_func = params['g_optimizer']\n",
        "        self.d_optim_func = params['d_optimizer']\n",
        "        self.state = {'stop_early':   False,\n",
        "                      'stop_criteria': 99.,\n",
        "                      'stop_step':    0,\n",
        "                      'epoch_index':  0,\n",
        "                      'best_epoch':   -1,\n",
        "                      'best_accu' :   -1,\n",
        "                      'test_loss':    -1,\n",
        "                      'test_accu':    -1,\n",
        "                      'g_train_epoch_loss': [],\n",
        "                      'g_train_epoch_accu': [],\n",
        "                      'g_train_batch_loss': [],\n",
        "                      'g_train_batch_accu': [],\n",
        "                      'd_train_epoch_loss': [],\n",
        "                      'd_train_epoch_accu': [],\n",
        "                      'd_train_batch_loss': [],\n",
        "                      'd_train_batch_accu': []}\n",
        "\n",
        "        self.criterion = PyTorchCall.map_torch_call(self.loss_func)()\n",
        "        \n",
        "        self.g_optimizer = PyTorchCall.map_torch_call(self.g_optim_func)()\n",
        "        self.g_optimizer = self.g_optimizer(g_model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "        \n",
        "        self.d_optimizer = PyTorchCall.map_torch_call(self.d_optim_func)()\n",
        "        self.d_optimizer = self.d_optimizer(d_model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "        \n",
        "        self.criterion.to(self.device)\n",
        "        \n",
        "        self.g_model.apply(self.weights_init)\n",
        "        self.d_model.apply(self.weights_init)\n",
        "     \n",
        "        self.fig = None\n",
        "        self.ax = None\n",
        "        self.gplot = None\n",
        "        self.dplot = None\n",
        "        \n",
        "        if hotstart:\n",
        "            model_state = torch.load(params['f_model_pth'])\n",
        "            self.g_model.load_state_dict(model_state['g_model_state_dict'])\n",
        "            self.d_model.load_state_dict(model_state['d_model_state_dict'])\n",
        "            for key, value in self.state.items():\n",
        "                self.state[key] = model_state[key]\n",
        "    \n",
        "\n",
        "    def train_loop(self, data):\n",
        "        \n",
        "        divider = '-' * 36\n",
        "        header  = '{:<16s}{:>10s}{:>10s}'\n",
        "        record  = '{:<16s}{:>10.3f}{:>10.3f}'\n",
        "              \n",
        "        print (divider)\n",
        "        print ('training')\n",
        "        print (divider)\n",
        "        \n",
        "        g_epoch_loss = 0. \n",
        "        g_epoch_accu = 0.\n",
        "        d_epoch_loss = 0. \n",
        "        d_epoch_accu = 0.    \n",
        "        \n",
        "        fixed_noise = torch.randn((36, self.latent_dim), device=self.device)\n",
        "        loss_plot = display(self.html_loss_plot('PLOT'), display_id=True)     \n",
        "        \n",
        "        # loop over epochs\n",
        "        for i_epoch in range(self.max_epochs):\n",
        "            \n",
        "            self.state['epoch_index'] = i_epoch\n",
        "            \n",
        "            epoch_loss = 0.\n",
        "            epoch_accu = 0.\n",
        "            \n",
        "            bar_train = display(self.html_progress('Train', 0, 100), display_id=True)\n",
        "              \n",
        "            for i_batch, (_, real_imgs, _) in enumerate(data['train']):\n",
        "                \n",
        "                # transfer to GPU\n",
        "                real_imgs = real_imgs.to(self.device)\n",
        "\n",
        "                # set up label for fake and real images\n",
        "                r = np.zeros((real_imgs.shape[0], 1))\n",
        "                fake = Variable(torch.tensor(r, device=self.device, dtype=torch.float), requires_grad=False)\n",
        "                r = np.ones((real_imgs.shape[0], 1))\n",
        "                real = Variable(torch.tensor(r, device=self.device, dtype=torch.float), requires_grad=False)\n",
        "\n",
        "\n",
        "                # --------------------\n",
        "                #  Train Discriminator\n",
        "                # --------------------\n",
        "                \n",
        "                self.d_optimizer.zero_grad()\n",
        "\n",
        "                predict_real = self.d_model(real_imgs)                \n",
        "                d_loss_real = self.criterion(predict_real, real)\n",
        "                d_loss_real.backward()\n",
        "                \n",
        "                # Measure discriminator's ability to classify real from generated samples\n",
        "                #r = np.random.normal(0, 1, (real_imgs.shape[0], self.latent_dim))\n",
        "                #z = Variable(torch.tensor(r, device=self.device, dtype=torch.float))\n",
        "                z = torch.randn((real_imgs.shape[0], self.latent_dim), device=self.device)\n",
        "                fake_imgs = self.g_model(z)\n",
        " \n",
        "                predict_fake = self.d_model(fake_imgs.detach())\n",
        "                d_loss_fake = self.criterion(predict_fake, fake)\n",
        "                d_loss_fake.backward()\n",
        "                \n",
        "                d_loss = 0.5*(d_loss_real + d_loss_fake)\n",
        "                \n",
        "                #predicts = torch.cat((predict_real, predict_fake))\n",
        "                #targets = torch.cat((real, fake))\n",
        "                #d_loss = self.criterion(predicts, targets) / 2.\n",
        "                #d_loss.backward()\n",
        "                \n",
        "                self.d_optimizer.step()\n",
        "                \n",
        "                d_batch_loss = d_loss.item()\n",
        "                d_epoch_loss += (d_batch_loss - d_epoch_loss) / (i_batch + 1)\n",
        "                \n",
        "                #d_batch_accu = self.accuracy(predicts, targets)\n",
        "                d_batch_accu = self.accuracy(predict_real, real)\n",
        "                d_batch_accu += self.accuracy(predict_fake, fake)\n",
        "                d_batch_accu = 0.5 * d_batch_accu \n",
        "                d_epoch_accu += (d_batch_accu - d_epoch_accu) / (i_batch + 1)\n",
        "\n",
        "                self.state['d_train_batch_loss'].append(d_batch_loss)\n",
        "                self.state['d_train_batch_accu'].append(d_batch_accu)   \n",
        "                \n",
        "                \n",
        "                # -----------------\n",
        "                #  Train Generator\n",
        "                # -----------------\n",
        "\n",
        "                self.g_optimizer.zero_grad()\n",
        "\n",
        "                # sample noise as generator input\n",
        "                #r = np.random.normal(0, 1, (real_imgs.shape[0], self.latent_dim))\n",
        "                #z = Variable(torch.tensor(r, device=self.device, dtype=torch.float))\n",
        "\n",
        "                # generate a batch of images\n",
        "                #fake_imgs = self.g_model(z)\n",
        "  \n",
        "                # loss measures generator's ability to fool the discriminator\n",
        "                predict_fake = self.d_model(fake_imgs)\n",
        "                g_loss = self.criterion(predict_fake, real)\n",
        "\n",
        "                g_loss.backward()\n",
        "                self.g_optimizer.step()\n",
        "\n",
        "                g_batch_loss = g_loss.item()\n",
        "                g_epoch_loss += (g_batch_loss - g_epoch_loss) / (i_batch + 1)\n",
        "                \n",
        "                g_batch_accu = self.accuracy(predict_fake, real)\n",
        "                g_epoch_accu += (g_batch_accu - g_epoch_accu) / (i_batch + 1)\n",
        "\n",
        "                self.state['g_train_batch_loss'].append(g_batch_loss)\n",
        "                self.state['g_train_batch_accu'].append(g_batch_accu)              \n",
        "                \n",
        "                pct_done = (i_batch+1)/len(data['train'])*100\n",
        "                bar_train.update(self.html_progress('Train', pct_done, 100))\n",
        "                #print ('{0:>3d}'.format(i_batch), end = ' ') \n",
        "                #if (i_batch+1)%30==0: print (' ')\n",
        "                #    #print (divider)\n",
        "                #    #print ('summary of i_batch:', i_batch+1)\n",
        "                #    #print (divider)\n",
        "                #    #print (header.format(' ', 'loss', 'accurary')) \n",
        "                #    #print (record.format('Generator', self.state['g_train_batch_loss'][-1], self.state['g_train_batch_accu'][-1]))\n",
        "                #    #print (record.format('Discriminator', self.state['d_train_batch_loss'][-1], self.state['d_train_batch_accu'][-1]))\n",
        "                               \n",
        "\n",
        "            self.state['g_train_epoch_loss'].append(g_epoch_loss)\n",
        "            self.state['g_train_epoch_accu'].append(g_epoch_accu) \n",
        "            self.state['d_train_epoch_loss'].append(d_epoch_loss)\n",
        "            self.state['d_train_epoch_accu'].append(d_epoch_accu)\n",
        " \n",
        "            print (' ')\n",
        "            # epoch summary\n",
        "            if i_epoch%1==0:\n",
        "                print (divider)\n",
        "                print ('summary of epoch:', i_epoch)\n",
        "                print (divider)\n",
        "                print (header.format(' ', 'loss', 'accurary')) \n",
        "                print (record.format('Generator', self.state['g_train_epoch_loss'][-1], self.state['g_train_epoch_accu'][-1]))\n",
        "                print (record.format('Discriminator', self.state['d_train_epoch_loss'][-1], self.state['d_train_epoch_accu'][-1]))\n",
        "                print (' ')\n",
        "                uri = self.update_loss_plot()\n",
        "                loss_plot.update(self.html_loss_plot(uri))\n",
        "                \n",
        "            if i_epoch%1==0:\n",
        "                self.update_loss_plot()\n",
        "                f_image = '/content/drive/My Drive/Colab Notebooks/deepTC/model/dcgan/image/images_{0}.png'.format(i_epoch)\n",
        "                fixed = self.g_model(fixed_noise)\n",
        "                save_image(fixed.data, f_image, nrow=6, normalize=True)\n",
        "            \n",
        "            self.update_save_state()\n",
        "            if self.state['stop_early']: break\n",
        "             \n",
        "        \n",
        "    def accuracy(self, predicts, targets):\n",
        "      \n",
        "        pred = predicts >= 0.5\n",
        "        truth = targets >= 0.5\n",
        "        n_correct = torch.eq(pred, truth).sum().item()\n",
        "        return n_correct / len(predicts) * 100\n",
        "      \n",
        "      \n",
        "    def html_loss_plot(self, image):\n",
        "        \n",
        "        h = HTML(\"\"\"<img src='{0}'/>\"\"\".format(image))\n",
        "    \n",
        "        return h\n",
        "\n",
        "    \n",
        "    def html_progress(self, var, value, max=100):\n",
        "        h = HTML(\"\"\"{var}: <progress value='{value}' max='{max}', style='width: 80%'>{value}\n",
        "                           </progress>\"\"\".format(var=var, value=value, max=max))\n",
        "    \n",
        "        return h\n",
        "    \n",
        "        \n",
        "    def update_loss_plot(self):\n",
        "        \n",
        "        g_batch_loss = self.state['g_train_batch_loss']\n",
        "        d_batch_loss = self.state['d_train_batch_loss']      \n",
        "        x = range(len(g_batch_loss))\n",
        "        \n",
        "        # initiate plot\n",
        "        fig, ax = plt.subplots() \n",
        "        ax.plot(x, g_batch_loss)\n",
        "        ax.plot(x, d_batch_loss)\n",
        "        \n",
        "        bio = io.BytesIO()\n",
        "        fig.savefig(bio, format='png')\n",
        "        bio.seek(0)\n",
        "        uri = 'data:image/png;base64,' + base64.encodebytes(bio.getvalue()).decode()\n",
        "\n",
        "        plt.close()\n",
        "        \n",
        "        return uri\n",
        "        \n",
        "        \n",
        "    def update_save_state(self):\n",
        "        \n",
        "        # save state\n",
        "        with open(self.f_state, 'w') as fp:\n",
        "            yaml.dump(self.state, fp)\n",
        "            \n",
        "        # save the model\n",
        "        state_cp = deepcopy(self.state)\n",
        "        state_cp['d_model_state_dict'] = self.d_model.state_dict()\n",
        "        state_cp['d_optim_state_dict'] = self.d_optimizer.state_dict()\n",
        "        state_cp['g_model_state_dict'] = self.g_model.state_dict()\n",
        "        state_cp['g_optim_state_dict'] = self.g_optimizer.state_dict()\n",
        " \n",
        "        torch.save(state_cp, self.f_model)\n",
        "  \n",
        "  \n",
        "    def weights_init(self, m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "            \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xr7zonbv0QLx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In place test code block to be commented out \n",
        "\n",
        "'''\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "work_dir = r'/content/drive/My Drive/Colab Notebooks/deepTC'\n",
        "p_data  = work_dir + os.sep + 'data/AL'\n",
        "p_image = work_dir + os.sep + 'image/AL'\n",
        "p_model = work_dir + os.sep + 'model/dcgan'\n",
        "\n",
        "# load configuration file\n",
        "f_config = p_model + os.sep + 'config_dcgan.yaml'\n",
        "with open(f_config, 'r') as fp: config = yaml.load(fp)\n",
        "  \n",
        "\n",
        "# update path for config\n",
        "config_params = config['params']\n",
        "config_params['f_image_zip'] = p_image + os.sep + config_params['f_image_zip']\n",
        "config_params['f_storm_msg'] = p_data  + os.sep + config_params['f_storm_msg']\n",
        "config_params['f_data_yml']  = p_model + os.sep + config_params['f_data_yml']\n",
        "config_params['f_state_yml'] = p_model + os.sep + config_params['f_state_yml']\n",
        "config_params['f_model_pth'] = p_model + os.sep + config_params['f_model_pth']\n",
        "config_params['f_test_yml']  = p_model + os.sep + config_params['f_test_yml']\n",
        "\n",
        "# contruct the model\n",
        "generator = YML2Model(config, 'generator')\n",
        "discriminator = YML2Model(config, 'discriminator')\n",
        "\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# dataset\n",
        "# filter HU3 data only \n",
        "f_img_msg = p_data + os.sep + 'al_ir_track_filtered.msg'\n",
        "f_hu1_msg = p_data + os.sep + 'al_ir_track_hu1.msg'\n",
        "pd_storm = pd.read_msgpack(f_img_msg) \n",
        "pd_storm = pd_storm[pd_storm[b'cat']==b'HU1']\n",
        "pd_storm.reset_index(drop=True)\n",
        "pd_storm.index = pd.RangeIndex(len(pd_storm.index))\n",
        "pd_storm.index = range(len(pd_storm.index))\n",
        "pd_storm.to_msgpack(f_hu1_msg)\n",
        "#print (pd_storm.head())\n",
        "\n",
        "storm_data = ImageDataSet(config_params, image_transforms, hotstart=False)\n",
        "data_split = storm_data.load_data()\n",
        "\n",
        "# model\n",
        "storm_train = ImageTrainerGAN(config_params, generator, discriminator, hotstart=False)\n",
        "\n",
        "# train & valid\n",
        "storm_train.train_loop(data_split)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}