{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepTC_net_image.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aachen6/deepTC/blob/master/colab/deepTC_net_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wk3zltbBVuNp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DeepTC - Post-binding Architecture\n",
        "\n",
        "The objective of *deepTC* can be found on [deepTC github page](https://github.com/aachen6/deepTC/), and the analysis is outlined below.\n",
        "1. Data Preprocess\n",
        " - 1.1 [Satellite images and tracks of TC](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_images_tracks_sync.ipynb)\n",
        " - 1.2 [Statistics of satellite images and tracks](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_images_tracks_stats.ipynb)\n",
        "\n",
        "2. Model for TC Image\n",
        " - **2.1 [Post-binding architecture of TC image](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_net_image.ipynb)**\n",
        " - 2.2 [CNN model for TC image classification ](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_classification_cnn5.ipynb)\n",
        " - 2.3 [Resnet model for TC image classification](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_classification_resnet.ipynb)\n",
        " - 2.4 [Resnet model for TC image intensity estimation](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_intensity_resnet.ipynb)\n",
        " - 2.5 [Operation of TC image prediction](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_image_prediction.ipynb)\n",
        "\n",
        "3. Model for TC Track\n",
        " - 3.1 [Post-binding architecture of TC track](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_net_track.ipynb)\n",
        " - 3.2 [LSTM model for TC track prediction](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_track_lstm.ipynb)\n",
        " - 3.3 [LSTM model with attension for TC track prediction](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_track_lstm.ipynb) \n",
        " - 3.4 [LSTM-CNN model for TC track prediction](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_track_lstmcnn.ipynb)\n",
        "\n",
        "4. Generative Model for TC Image\n",
        " - 4.1 [DCGAN model for deepTC](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_generative_dcgan.ipynb)\n",
        " - 4.2 [SAGAN model for deepTC](https://github.com/aachen6/deepTC/blob/master/colab/deepTC_generative_sagan.ipynb)\n",
        " \n",
        "Now, the best track and satellite image dataset of the historical TC are ready from the first two notebooks. This notebook will cover architecture of *deepTC*, which is based on *pytorch*. To explore different deep neural network architectures efficiently,  *deepTC* features post-binding deep neutral network architecture from a configuration file without the need of code revision. Let's start with importing the necessary python modules, particularly installing pytorch with GPU support on *Google Colab*."
      ]
    },
    {
      "metadata": {
        "id": "DIhxSG4TKW8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# basics\n",
        "import os\n",
        "import yaml\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "# intall an early verison of pillow, as the latest pillow cause an error \n",
        "# when loading images from zip file\n",
        "!pip install pillow==4.1.1\n",
        "\n",
        "# handling the images\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# install and load pytorch\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.enabled = False  # cudnn doesn't seem to work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iswBDxJRL8JF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Post-Binding Deep Neutral Network\n",
        "\n",
        "It's beneficial to test different architectures of deep netural network. To improve the efficiency of the process, let's decouple the model construction from the code by post-binding the deep neutral network from a configuration file. A *YAML* configuration file is used to define the architecture of the deep netural network. Two classes are created to construct the deep neutral network based on the *YAML* configuration file, i.e. a static class mapping method string names to pytorch methods or class instances and a pytorch module subclass to generate the model instance. Currently, sequential model with an extension to have residual block/net is implemented. It is straightforward to extend the idea to include more complex deep neutral network architectures. \n",
        "\n",
        "The first class *PyTorchCall* is simply a static class that maps pytorch methods based on their string names with the corresponding arguements. Only the necessary methods for the current application are included at this moment. The implementation is very straightforward utilizing *python getattr* method. \n",
        "\n",
        "~~~python\n",
        "class PyTorchCall:\n",
        "     def map_torch_call(func_str):\n",
        "          return getattr(PytorchCall, '_' + func_str)\n",
        "     # any pytorch calls to be added below\n",
        "~~~"
      ]
    },
    {
      "metadata": {
        "id": "Z4iLs9RIMWOm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PyTorchCall:\n",
        "\n",
        "    # will update to unroll function variables using **kwarg\n",
        "  \n",
        "    @staticmethod\n",
        "    def map_torch_call(func_str): return getattr(PyTorchCall, '_' + func_str)\n",
        "\n",
        "    # pytorch nn calls\n",
        "    @staticmethod \n",
        "    def _linear(args): return nn.Linear(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _dropout(args): return nn.Dropout(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _conv2d(args):\n",
        "        return nn.Conv2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _deconv2d(args):\n",
        "        return nn.ConvTranspose2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _upsample(args):\n",
        "        return nn.Upsample(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _batchnorm2d(args):\n",
        "        return nn.BatchNorm2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod     \n",
        "    def _avgpool2d(args):\n",
        "        return nn.AvgPool2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod    \n",
        "    def _maxpool2d(args):\n",
        "        return nn.MaxPool2d(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _lstm(args):\n",
        "        return nn.LSTM(*args['args'], **args['kwargs'])\n",
        " \n",
        "    @staticmethod\n",
        "    def _relu(args):\n",
        "        return nn.ReLU(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _tanh(args):\n",
        "        return nn.Tanh(*args['args'], **args['kwargs'])\n",
        "    @staticmethod\n",
        "    def _sigmoid(args):\n",
        "        return nn.Sigmoid(*args['args'], **args['kwargs'])\n",
        "    @staticmethod \n",
        "    def _leakyrelu(args):\n",
        "        return nn.LeakyReLU(*args['args'], **args['kwargs'])\n",
        "\n",
        "    # pytorch functional\n",
        "    #@staticmethod\n",
        "    #def _relu(args): return F.relu\n",
        "    @staticmethod \n",
        "    def _batchnorm(args): return F.batch_norm\n",
        "    @staticmethod\n",
        "    def _softmax(args): return F.softmax\n",
        "\n",
        "    @staticmethod\n",
        "    def _view1d(args): return  \n",
        "    @staticmethod\n",
        "    def _view2d(args): return\n",
        "    \n",
        "    @staticmethod\n",
        "    def _pad_packed(args): return\n",
        "    @staticmethod\n",
        "    def _pack_padded(args): return\n",
        "      \n",
        "    # pytorch loss\n",
        "    @staticmethod\n",
        "    def _l1loss(): return nn.L1Loss()\n",
        "    @staticmethod\n",
        "    def _mseloss(): return nn.MSELoss() \n",
        "    @staticmethod\n",
        "    def _bceloss(): return nn.BCELoss()\n",
        "    @staticmethod\n",
        "    def _crossentropy(): return nn.CrossEntropyLoss() \n",
        "\t\t\n",
        "    # pytorch optimiter\n",
        "    @staticmethod\n",
        "    def _sgd(): return optim.SGD\n",
        "    @staticmethod\n",
        "    def _adam(): return optim.Adam\n",
        "\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkfdlpxZZkBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The second class *YML2ModelNet* inherits pytoch *nn.Module* that is designed to generate pytorch model instance based on the *YAML* configuration file. The configuration file defines each layer of deep neutral network according to pytorch *nn.Module*. An example of two-layer convolution network is shown below,\n",
        "\n",
        "~~~yaml\n",
        "model: \n",
        "  cnn2:\n",
        "   - layer1-sequential: # groupd into sequential but can be expanded out into each layer\n",
        "      - conv2d:\n",
        "          args: [1, 32, 3]\n",
        "          kwargs: [padding: 1, stride: 1]\n",
        "      - maxpool2d:\n",
        "          args: [2]\n",
        "          kwargs: [padding: 0, stride: 2]\n",
        "      - relue:\n",
        "          args: []\n",
        "          kwargs: {}\n",
        "  - layer2-sequential:\n",
        "      - conv2d:\n",
        "          args: [32, 32, 3]\n",
        "          kwargs: [padding: 1, stride: 1]\n",
        "      - maxpool2d:\n",
        "          args: [2]\n",
        "          kwargs: [padding: 0, stride: 2]\n",
        "      - relue:\n",
        "          args: []\n",
        "          kwargs: {}        \n",
        "  - layer3-view:\n",
        "      args: []\n",
        "      kwargs: {}\n",
        "  - layer4-linear:\n",
        "      args: [8192, 10]\n",
        "      kwargs: {}\n",
        "~~~\n",
        "\n",
        "The pytorch module subclass should inherit *nn.Mudule* and define the following methods:\n",
        "\n",
        "~~~python\n",
        "__init__ : # define layer as class variable\n",
        "__forward__: # forward loop for the network \n",
        "~~~\n",
        "The *init* method construct each layer as its class variable, which are eventually used in the forward method. *View* method is included as a layer which is handled seperately. Alternatively, this method can be wrapped into a separate pytorch *nn.Module* subclass. Separate classes are also created inheriting *nn.Module* for special or non-sequential network components, which are used as building blocks in the model. Currently, such special classes include an extension of RNN layer and a residual block for residual network. It is straightforward to extend the idea to generate more complex deep neutral network architectures, such as embedding, attension etc., which will be covered in later notebooks."
      ]
    },
    {
      "metadata": {
        "id": "czaoyxXvPafO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class YML2ModelNet(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, config, model_name):\n",
        "      \n",
        "        super(YML2ModelNet, self).__init__()\n",
        "      \n",
        "        self.layers = []\n",
        "        cfg_model = config['models'][model_name] \n",
        "        \n",
        "        for lyr_cfg in cfg_model:\n",
        "          \n",
        "            # get current layer name, type, and arguments\n",
        "            lyr_key = list(lyr_cfg.keys())[0]\n",
        "            [lyr_name, lyr_type] = lyr_key.split('-')\n",
        "            \n",
        "            # get layer argument in place or outside model scope            \n",
        "            lyr_args = lyr_cfg[lyr_key]\n",
        "            if lyr_args=='None': lyr_args = config[lyr_key]            \n",
        "                \n",
        "            if lyr_type in ['rnn','gru', 'lstm']:\n",
        "                n_hidden = lyr_args['args'][1] \n",
        "                n_layers = lyr_args['kwargs']['num_layers']\n",
        "                lyr_ts = self.yml2lyr(lyr_type, lyr_args)\n",
        "                lyr_inst = RnnTS(lyr_type, n_hidden, n_layers, lyr_ts)\n",
        "              \n",
        "            elif lyr_type=='resblock':\n",
        "                key_args = {}\n",
        "                for _key, _args in lyr_args.items():\n",
        "                    [_name, _type] = _key.split('-')\n",
        "                    key_args[_name] = [_type, _args]\n",
        "                residual = self.yml2lyr(*key_args['residual'])\n",
        "                identity = self.yml2lyr(*key_args['identity'])\n",
        "                activate = self.yml2lyr(*key_args['activate'])\n",
        "                lyr_inst = ResBlock(residual, identity, activate)\n",
        "              \n",
        "            else:  # nn module layer\n",
        "                lyr_inst = self.yml2lyr(lyr_type, lyr_args)\n",
        "              \n",
        "            # register layer to the class \n",
        "            setattr(self, lyr_name, lyr_inst)\n",
        "            lyr_ref = getattr(self, lyr_name)\n",
        "            self.layers.append([lyr_type, lyr_args, lyr_ref]) \n",
        "                       \n",
        "            \n",
        "    def yml2lyr(self, lyr_type, lyr_args):\n",
        "            \n",
        "        if lyr_type=='sequential':\n",
        "            modules = []\n",
        "            for row in lyr_args:\n",
        "                r_func = list(row.keys())[0]\n",
        "                r_args = row[r_func]                  \n",
        "                r_module = PyTorchCall.map_torch_call(r_func)(r_args)\n",
        "                modules.append(r_module)\n",
        "            lyr_obj = nn.Sequential(*modules)\n",
        "            \n",
        "        else: # individual nn.module\n",
        "            lyr_obj = PyTorchCall.map_torch_call(lyr_type)(lyr_args) \n",
        "       \n",
        "        return lyr_obj             \n",
        "              \n",
        "\n",
        "    def forward(self, x, seq_mask=None):      \n",
        "        # implementation of Module forward method\n",
        "        for i, (lyr_type, ly_arg, lyr_ref) in enumerate(self.layers):\n",
        "\n",
        "            if lyr_type=='view1d': \n",
        "                n = int(np.prod(x.size()[1:]))\n",
        "                x = x.view(-1, n)\n",
        "              \n",
        "            elif lyr_type=='view2d':\n",
        "                kwargs = ly_arg['kwargs']\n",
        "                x = x.view(x.size()[0], kwargs['channel'], kwargs['size'], kwargs['size'])\n",
        "                \n",
        "            elif lyr_type in ['rnn', 'gru', 'lstm']:\n",
        "                x = lyr_ref(x, seq_mask)\n",
        "                \n",
        "            else: # nn module and subclass\n",
        "                x = lyr_ref(x)\n",
        "                \n",
        "        return x              \n",
        "            \n",
        "\n",
        "      \n",
        "class RnnTS(torch.nn.Module):              \n",
        "    def __init__(self, lyr_type, n_hidden, n_layer, lyr_obj):\n",
        "      \n",
        "        super(RnnTS, self).__init__()\n",
        "        \n",
        "        self.layer = lyr_obj\n",
        "        self.lyr_type = lyr_type\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layer  = n_layer\n",
        "              \n",
        "    def init_hidden(self, batch_size, device):\n",
        "      \n",
        "        if self.lyr_type == 'lstm':  # currently, only LSTM model is implemented\n",
        "            self.h = torch.zeros(self.n_layer, batch_size, self.n_hidden)\n",
        "            self.c = torch.zeros(self.n_layer, batch_size, self.n_hidden)\n",
        "            \n",
        "        self.h = self.h.to(device)\n",
        "        self.c = self.c.to(device)\n",
        "        \n",
        "        return\n",
        "      \n",
        "    def forward(self, x, seq_mask=None):\n",
        "      \n",
        "        batch_size = x.size()[0]\n",
        "        device = x.get_device() if x.is_cuda else 'cpu'  \n",
        "    \n",
        "        if seq_mask is not None: # mask for sequences with different length       \n",
        "            x = nn.utils.rnn.pack_padded_sequence(x, seq_mask, batch_first=True)   \n",
        "       \n",
        "        self.init_hidden(batch_size, device)\n",
        "        x, (self.h, self.c) = self.layer(x, (self.h, self.c))\n",
        "        \n",
        "        if seq_mask is not None:\n",
        "            x, _ = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)                \n",
        "\n",
        "        return x          \n",
        "      \n",
        "      \n",
        "class ResBlock(torch.nn.Module):\n",
        "   \n",
        "    def __init__(self, residual, identity, activate):\n",
        "      \n",
        "        super(ResBlock, self).__init__()\n",
        "        \n",
        "        self.residual = residual  # sequential residual mapping\n",
        "        self.identity = identity  # identify mapping of input\n",
        "        self.activate = activate  # activation\n",
        "        \n",
        "    def forward(self, x):\n",
        " \n",
        "        residual = self.residual(x)\n",
        "        x = self.identity(x)\n",
        "        x += residual\n",
        "        x = self.activate(x)\n",
        "                \n",
        "        return x            \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8Rh-OBsMPrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Storm Dataset Class\n",
        "\n",
        "A lot of effort in solving any machine learning problem goes into data preparation. To simplify the process, the dataset shall be a *Pandas DataFrame*, and the column name for input and target variable(s) shall be specified in the configuration file. Any image data shall be specified with the file path. *ImageDataSet* is created that inherits pytorch *Dataset* class and handles data preparation before feeding into the training. According to pytorch document, the custom dataset class should inherit *Dataset* and override the following methods:\n",
        "\n",
        "~~~python\n",
        "__len__ : # so that len(dataset) returns the size of the dataset.\n",
        "__getitem__: # to support the indexing such that dataset can be used to get ith sample\n",
        "~~~\n",
        "\n",
        "The *getitem* method returns training input and target, and the corresponding index, which can be used later during the post-processing, e.g. to idenfity mis-classified images from confusion matrix. A data split method is also implemented to split the data into training, validation, and test set. As shown earlier, the number of samples for each class are not well-balanced, therefore, an option with label aware is included, which can be enabled to preserve the ratio of sample size of each class within training, validation, and testing sets. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SO7xuF33MW_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "class ImageDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, config, transform=None, cats=None, hotstart=False):\n",
        "        \n",
        "        self.model_object = config['model_object']\n",
        "        self.batch_size   = config['batch_size']\n",
        "        self.col_input    = config['col_input']\n",
        "        self.col_target   = config['col_target']\n",
        "        self.n_workers    = config['n_workers']\n",
        "        \n",
        "        # read input files\n",
        "        f_storm_msg = config['f_storm_msg']\n",
        "        self.pd_storm = pd.read_msgpack(f_storm_msg)\n",
        "        \n",
        "        # load image archive\n",
        "        if self.col_input=='image':\n",
        "            f_image_zip = config['f_image_zip']\n",
        "            self.img_archv = ZipFile(f_image_zip, 'r')\n",
        "            # define transformation    \n",
        "            self.transform = transform\n",
        "        \n",
        "        # train valid test split\n",
        "        f_data_yml = config['f_data_yml']\n",
        "        if hotstart: # read from file\n",
        "            with open(f_data_yml, 'rb') as fp: \n",
        "                data = yaml.load(fp)\n",
        "                self.data_indices = data['indices']\n",
        "                if 'class' in self.model_object:\n",
        "                    self.one_hot_key = data['one_hot_key'] \n",
        "                    self.one_hot_rev = data['one_hot_rev'] \n",
        "                    \n",
        "        else: # create a new split\n",
        "            if 'class' in self.model_object:\n",
        "                # define one hot key map\n",
        "                self.one_hot_key = {}\n",
        "                self.one_hot_rev = {}\n",
        "                if cats is None:\n",
        "                    cats = set(self.pd_storm[self.col_target].tolist())\n",
        "                    cats = sorted(list(cats))\n",
        "                for i, cat in enumerate(sorted(cats)):\n",
        "                    self.one_hot_key[cat] = i\n",
        "                    self.one_hot_rev[i]   = cat\n",
        "            \n",
        "            # train validation split\n",
        "            self.data_indices = self.train_valid_test(config)\n",
        "\n",
        "            data = {} # save dataset\n",
        "            data['indices'] = self.data_indices  \n",
        "            if 'class' in self.model_object:\n",
        "                data['one_hot_key'] = self.one_hot_key\n",
        "                data['one_hot_rev'] = self.one_hot_rev            \n",
        "                      \n",
        "            with open(f_data_yml, 'w') as fp: \n",
        "                yaml.dump(data, fp)\n",
        "            \n",
        "        # summary of dataset\n",
        "        valid_pct = 1.- config['valid_pct']\n",
        "        test_pct  = 1. - config['test_pct']\n",
        "        n_train   = len(self.data_indices['train'])\n",
        "        n_valid   = len(self.data_indices['valid'])\n",
        "        n_test    = len(self.data_indices['test'])\n",
        "        batch     = self.batch_size\n",
        "        \n",
        "        divider = '-' * 36\n",
        "        header  = '{:<10s}{:>10s}{:>10s}{:>10s}'\n",
        "        record1 = '{:<10s}{:>10.2f}{:>10.2f}{:>10.2f}'\n",
        "        record2 = '{:<10s}{:>10d}{:>10d}{:>10d}'\n",
        "\n",
        "        print (divider)\n",
        "        print ('summary of dataset')\n",
        "        print (divider)\n",
        "        print (header.format(' ', 'train', 'valid', 'test')) \n",
        "        print (record1.format('percent', test_pct*valid_pct, test_pct*(1-valid_pct), 1-test_pct))\n",
        "        print (record2.format('size', n_train, n_valid, n_test))\n",
        "        print (record2.format('batch', int(n_train/batch), int(n_valid/batch), int(n_test/batch)))\n",
        "\n",
        "        return            \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.pd_storm[0].count()\n",
        "            \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        col_input  = self.col_input\n",
        "        col_target = self.col_target\n",
        "        row = self.pd_storm.iloc[idx]\n",
        "\n",
        "        # input\n",
        "        if self.col_input=='image':\n",
        "            image = row[col_input]\n",
        "            temp = image.split('.')[0].split('_')\n",
        "            f_image = temp[0] + '_' + temp[1] + '.jpg'\n",
        "            sample = Image.open(self.img_archv.open(f_image))\n",
        "            if self.transform is not None: \n",
        "                sample = self.transform(sample)\n",
        "        else:\n",
        "            sample = torch.FloatTensor(row[col_input].values)\n",
        "          \n",
        "        # target\n",
        "        if 'class' in self.model_object:\n",
        "            cat = row[col_target]          \n",
        "            target = self.one_hot_key[cat]   # no need to create one hot for pytorch\n",
        "        \n",
        "        if self.model_object=='regression':\n",
        "            if isinstance(col_target, list):\n",
        "                target = torch.FloatTensor(row[col_target].values)\n",
        "            else:\n",
        "                target = torch.FloatTensor([row[col_target]])\n",
        "                \n",
        "        return idx, sample, target \n",
        "\t\t\n",
        "    \n",
        "    def random_split(self, indices, pct, label_aware=None, shuffle=True, seed=64):\n",
        "      \n",
        "        # creating data indices for two splits:\n",
        "        indices_1 = []  # first half of the indices\n",
        "        indices_2 = []  # second half of the indices\n",
        "        if label_aware is not None:\n",
        "            pd_sub = self.pd_storm.iloc[indices]\n",
        "            cats = set(self.pd_storm[label_aware].tolist())\n",
        "            for cat in cats:\n",
        "                sub_indices = pd_sub[pd_sub[label_aware]==cat].index.tolist()\n",
        "                if shuffle: \n",
        "                    np.random.seed(seed)\n",
        "                    np.random.shuffle(sub_indices)\n",
        "                isplit = int(np.floor(len(sub_indices)*pct))            \n",
        "                indices_1 = indices_1 + sub_indices[:isplit]\n",
        "                indices_2 = indices_2 + sub_indices[isplit:]\n",
        "        else:\n",
        "            if shuffle: \n",
        "                np.random.seed(seed)\n",
        "                np.random.shuffle(indices)\n",
        "            isplit = int(np.floor(len(indices)*pct))            \n",
        "            indices_1 = indices_1 + indices[:isplit]\n",
        "            indices_2 = indices_2 + indices[isplit:]\n",
        "                \n",
        "        return indices_1,  indices_2\n",
        "                       \n",
        "        \n",
        "    def train_valid_test(self, config):\n",
        "        \n",
        "        data_indices = {} \n",
        "        valid_pct = 1. - config['valid_pct']\n",
        "        test_pct  = 1. - config['test_pct']\n",
        "        label_aware = config['label_aware']\n",
        "        shuffle = config['shuffle'] \n",
        "        seed = config['seed'] #+100\n",
        "        \n",
        "        indices = self.pd_storm.index.tolist()\n",
        "        \n",
        "        if config['test_pct'] is None:\n",
        "            test_indices = None\n",
        "            train_indices, valid_indices = self.random_split(indices, valid_pct, label_aware, shuffle, seed)\n",
        "        else:\n",
        "            _indices, test_indices = self.random_split(indices, test_pct, label_aware, shuffle)\n",
        "            train_indices, valid_indices = self.random_split(_indices, valid_pct, label_aware, shuffle, seed) \n",
        "            \n",
        "        data_indices['train'] = train_indices\n",
        "        data_indices['valid'] = valid_indices\n",
        "        data_indices['test'] = test_indices\n",
        "            \n",
        "        return data_indices\n",
        "\n",
        "      \n",
        "    def load_data(self):\n",
        "      \n",
        "        data_split = {} \n",
        "        \n",
        "        batch_size = self.batch_size\n",
        "        n_workers = self.n_workers\n",
        "       \n",
        "        train_indices = self.data_indices['train']\n",
        "        valid_indices = self.data_indices['valid']\n",
        "        test_indices  = self.data_indices['test']\n",
        "            \n",
        "        train_sampler = SubsetRandomSampler(train_indices)\n",
        "        valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "\n",
        "        data_split['train'] = DataLoader(self, batch_size=batch_size, sampler=train_sampler, num_workers=n_workers)\n",
        "        data_split['valid'] = DataLoader(self, batch_size=batch_size, sampler=valid_sampler, num_workers=n_workers)        \n",
        "        \n",
        "        if test_indices is None:\n",
        "            data_split['test'] = None \n",
        "        else:\n",
        "            test_sampler = SubsetRandomSampler(test_indices)  \n",
        "            data_split['test'] = DataLoader(self, batch_size=batch_size, sampler=test_sampler, num_workers=n_workers)\n",
        "        \n",
        "        return data_split\n",
        "      \n",
        "     \n",
        "    def normalization_factor(self, sample_a, sample_b):\n",
        "      \n",
        "        (n_a, mean_a, std_a) = sample_a\n",
        "        (n_b, mean_b, std_b) = sample_b\n",
        "  \n",
        "        n_c = n_a + n_b\n",
        "        mean_c = n_a*mean_a + n_b*mean_b\n",
        "        mean_c = mean_c/n_c\n",
        "  \n",
        "        numerator = (n_a-1)*std_a**2. + (n_b-1)*std_b**2. + \\\n",
        "                    n_a*(mean_a-mean_c)**2. + n_b*(mean_b-mean_c)**2.\n",
        "  \n",
        "        denorminator = n_c - 1\n",
        "  \n",
        "        std_c = np.sqrt(numerator/denorminator)\n",
        "  \n",
        "        return np.array([n_c, mean_c, std_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsobgYV5RBbf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Image Training Class\n",
        "\n",
        "This is where things start to get interesting. The trainer class links everything together and perform training to optimize the network based on loss objective. During the initialization of the training instance,  parameters like number of epoch, batch size, loss funcation etc. are passed from the configuration file. Some state parameters are also initialized to document the training state for assessment of model training/performance, such as training_batch_loss, training_batch_accuracy etc. The model net is passed to the training class, and the loss function and optimizer are initialized based on the configuration file. Finally, we simply have to loop through our data iterator, and feed the inputs to the network and optimize. \n",
        "~~~python\n",
        "for i_epoch in range(self.max_epochs):\n",
        "    for i_batch, (_, images, labels) in enumerate(data['train']): \n",
        "        self.optimizer.zero_grad()  # set the gradient to zero \n",
        "        predicts = self.model(images)  # make prediction\n",
        "        loss = self.criterion(predicts, labels)  # calculate loss \n",
        "        loss.backward() # backpropagation to get the weight update\n",
        "        self.optimizer.step() # update weight using the optimizer\n",
        "~~~\n",
        "During the training, we follow the approach similar to [this tutorial](https://github.com/GokuMohandas/practicalAI/blob/master/notebooks/11_Convolutional_Neural_N`etworks.ipynb) by Goku Mohandas to calculate the running epoch loss and accuracy. \n",
        "~~~python\n",
        "batch_accu = self.accuracy(predicts, labels)\n",
        "epoch_accu += (batch_accu - epoch_accu) / (i_batch + 1)\n",
        "~~~              \n",
        "Depending on the number of parameters, it may take a long time to run. It would be cost-efficient to detect early stopping if the proposed architecture does work well for the problem.  In order to check the process and performance of the training while it's running, two methods are implemented, i.e. a method to show progress bar for each epoch and a method for dynamic visualization of batch and running epoch loss and accuracy. Those methods embed html in the notebook that will be refreshing dynamically during the training.\n",
        "\n",
        "~~~python\n",
        "def html_loss_plot(self, image):\n",
        "    return  HTML(\"<img src='{0}'/>\".format(image))\n",
        "  \n",
        "def html_progress(self, var, value, max=100):\n",
        "    return HTML(\"\"\"{var}: <progress value='{value}' max='{max}', style='width: 80%'>{value}\n",
        "                            </progress>\"\"\".format(var=var, value=value, max=max))\n",
        " ~~~\n",
        "During the training, the state parameters will be saved into a file for post-process and/or hotstart the training. The model dict state will be saved as well using *torch.save* method.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "V4Ep0RGLRCNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "\n",
        "class ImageTrainer(object):\n",
        "    def __init__(self, params, model, hotstart=False):\n",
        "        # CUDA for PyTorch\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
        "        if self.device!='cpu':\n",
        "            divider = '-' * 36\n",
        "            print(divider)\n",
        "            print('summary of GPU')\n",
        "            print(divider)\n",
        "            print(torch.cuda.get_device_name(0))\n",
        "            print('Memory Usage:')\n",
        "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "            print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "        else:\n",
        "            print('training with cpu')   \n",
        " \n",
        "        # model objective\n",
        "        self.model_object = params['model_object']\n",
        "        self.col_target = params['col_target']\n",
        "\n",
        "        # hyper params\n",
        "        self.max_epochs = params['max_epochs']\n",
        "        self.batch_size = params['batch_size']\n",
        "        self.r_learning = params['r_learning']\n",
        "        self.loss_func  = params['loss_func']\n",
        "        self.optim_func = params['optimizer']\n",
        " \n",
        "        # path for output\n",
        "        self.f_state    = params['f_state_yml']\n",
        "        self.f_model    = params['f_model_pth']\n",
        "        self.f_test     = params['f_test_yml']\n",
        "        \n",
        "        # training state \n",
        "        self.state = {'stop_early':   False,\n",
        "                      'stop_criteria': 99.9,\n",
        "                      'stop_step':    0,\n",
        "                      'epoch_index':  0,\n",
        "                      'best_epoch':   -1,\n",
        "                      'best_accu' :   -1,\n",
        "                      'test_loss':    -1,\n",
        "                      'test_accu':    -1,\n",
        "                      'train_epoch_loss': [],\n",
        "                      'train_epoch_accu': [],\n",
        "                      'train_batch_loss': [],\n",
        "                      'train_batch_accu': [],\n",
        "                      'valid_epoch_loss': [],\n",
        "                      'valid_epoch_accu': [],\n",
        "                      'valid_batch_loss': [],\n",
        "                      'valid_batch_accu': []}\n",
        "\n",
        "        # model\n",
        "        self.model = model.to(self.device)\n",
        "        # loss\n",
        "        self.criterion = PyTorchCall.map_torch_call(self.loss_func)()\n",
        "        # optimizer\n",
        "        self.optimizer = PyTorchCall.map_torch_call(self.optim_func)()\n",
        "        self.optimizer = self.optimizer(model.parameters(), lr=self.r_learning)\n",
        "        \n",
        "        if hotstart: # hotstart \n",
        "            model_state = torch.load(params['f_model_pth'])\n",
        "            self.model.load_state_dict(model_state['model_state_dict'])\n",
        "            for key, value in self.state.items():\n",
        "                self.state[key] = model_state[key]\n",
        "    \n",
        "\n",
        "    def train_loop(self, data):\n",
        "        \n",
        "        divider = '-' * 36\n",
        "        print (divider)\n",
        "        print ('training')\n",
        "        print (divider)\n",
        "        \n",
        "        loss_plot = display(self.html_loss_plot('PLOT'), display_id=True)\n",
        "        \n",
        "        # loop over epochs\n",
        "        for i_epoch in range(self.max_epochs):\n",
        "            \n",
        "            self.state['epoch_index'] = i_epoch\n",
        "            \n",
        "            # training\n",
        "            epoch_loss = 0.\n",
        "            epoch_accu = 0.\n",
        "            self.model.train()\n",
        "            bar_train = display(self.html_progress('Train', 0, 100), display_id=True)\n",
        "            for i_batch, (_, inputs, targets) in enumerate(data['train']):\n",
        "\n",
        "                # transfer to GPU\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                \n",
        "                # model computations\n",
        "                self.optimizer.zero_grad()\n",
        "                predicts = self.model(inputs)\n",
        " \n",
        "                loss = self.criterion(predicts, targets)\n",
        "                batch_loss = loss.item()\n",
        "                epoch_loss += (batch_loss - epoch_loss) / (i_batch + 1)\n",
        "                \n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                batch_accu = self.accuracy(predicts, targets)\n",
        "                epoch_accu += (batch_accu - epoch_accu) / (i_batch + 1)\n",
        "                \n",
        "                self.state['train_batch_loss'].append(batch_loss)\n",
        "                self.state['train_batch_accu'].append(batch_accu)\n",
        "\n",
        "                pct_done = (i_batch+1)/len(data['train'])*100\n",
        "                bar_train.update(self.html_progress('Train', pct_done, 100))\n",
        "\n",
        "            self.state['train_epoch_loss'].append(epoch_loss)\n",
        "            self.state['train_epoch_accu'].append(epoch_accu)\n",
        "  \n",
        "            # validation\n",
        "            epoch_loss = 0.\n",
        "            epoch_accu = 0.\n",
        "            self.model.eval()\n",
        "            bar_valid = display(self.html_progress('Valid', 0, 100), display_id=True)\n",
        "            for i_batch, (_, inputs, targets) in enumerate(data['valid']):\n",
        "                # transfer to GPU\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                \n",
        "                # model computations\n",
        "                predicts = self.model(inputs)\n",
        " \n",
        "                loss = self.criterion(predicts, targets)\n",
        "                batch_loss = loss.item()\n",
        "                epoch_loss += (batch_loss - epoch_loss) / (i_batch + 1)\n",
        "                \n",
        "                batch_accu = self.accuracy(predicts, targets)\n",
        "                epoch_accu += (batch_accu - epoch_accu) / (i_batch + 1)\n",
        "                \n",
        "                self.state['valid_batch_loss'].append(batch_loss)\n",
        "                self.state['valid_batch_accu'].append(batch_accu)\n",
        "                \n",
        "                pct_done = (i_batch+1)/len(data['valid'])*100\n",
        "                bar_valid.update(self.html_progress('Valid', pct_done, 100))                \n",
        "                \n",
        "            self.state['valid_epoch_loss'].append(epoch_loss)\n",
        "            self.state['valid_epoch_accu'].append(epoch_accu)\n",
        "                        \n",
        "            # epoch summary\n",
        "            header   = '{:<12s}{:>10s}{:>10s}'\n",
        "            n_target = len(self.col_target) if isinstance(self.col_target, list) else 1\n",
        "            record1  = '{:<12s}' + \"{:>10.3f}\"*2\n",
        "            record2  = '{:<12s}' + \"{:>10.3f}\"*n_target\n",
        "            \n",
        "            if i_epoch%1==0:\n",
        "                print (divider)\n",
        "                print ('summary of epoch:', i_epoch)\n",
        "                print (divider)\n",
        "                print (header.format('loss - ', 'train', 'valid')) \n",
        "                print (record1.format(' ', self.state['train_epoch_loss'][-1], self.state['valid_epoch_loss'][-1]))\n",
        "                print ('accuracy/error - ')\n",
        "                if isinstance(self.col_target, list):\n",
        "                    row = self.state['train_epoch_accu'][-1]\n",
        "                    if isinstance(row, float): row = [row]\n",
        "                    print (record2.format('train', *row))\n",
        "                    row = self.state['valid_epoch_accu'][-1]\n",
        "                    if isinstance(row, float): row = [row]\n",
        "                    print (record2.format('valid', *row))\n",
        "                else:\n",
        "                    print (record1.format(' ', self.state['train_epoch_accu'][-1], self.state['valid_epoch_accu'][-1]))                \n",
        "                \n",
        "                uri = self.update_loss_plot()\n",
        "                loss_plot.update(self.html_loss_plot(uri))\n",
        "                print (' ')\n",
        "            \n",
        "            self.update_save_state()\n",
        "            if self.state['stop_early']: break\n",
        "             \n",
        "        \n",
        "    def test_loop(self, data, apply_softmax=False):\n",
        "        total = 0\n",
        "        correct = 0.\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i_batch, (idxs, inputs, targets) in enumerate(data['test']):\n",
        "              \n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                predicts = self.model(inputs)\n",
        "                if apply_softmax: predicts  = F.softmax(predicts, 1) \n",
        "\n",
        "                total += int(targets.size(0))\n",
        "                batch_accu = self.accuracy(predicts, targets)\n",
        "                correct += (batch_accu - correct) / (i_batch + 1)   \n",
        "\n",
        "                if 'class' in self.model_object:\n",
        "                    _, predicts = torch.max(predicts.data, 1)\n",
        "                    \n",
        "                if i_batch==0: \n",
        "                    test_idxs = idxs.data\n",
        "                    test_targets = targets.data\n",
        "                    test_predicts = predicts.data\n",
        "                else:\n",
        "                    test_idxs = torch.cat((test_idxs, idxs.data))\n",
        "                    test_targets = torch.cat((test_targets, targets.data))\n",
        "                    test_predicts = torch.cat((test_predicts, predicts.data))\n",
        "                        \n",
        "        test_idxs = test_idxs.cpu().detach().numpy()\n",
        "        test_targets = test_targets.cpu().detach().numpy()\n",
        "        test_predicts = test_predicts.cpu().detach().numpy()\n",
        "       \n",
        "        # test summary\n",
        "        divider = '-' * 36\n",
        "        print(divider)\n",
        "        print('summary of test')\n",
        "        print(divider)\n",
        "        print('{:<10s}{:>10s}{:>10s}'.format('', 'total', 'accuracy'))\n",
        "        print('{:<10s}{:>10d}{:>10.3f}'.format('test', total, correct))    \n",
        "        \n",
        "        # save test\n",
        "        test_results = {}\n",
        "        test_results['idxs'] = test_idxs\n",
        "        test_results['labels'] = test_targets\n",
        "        test_results['predicts'] = test_predicts\n",
        "        test_results['accuracy'] = correct\n",
        "        \n",
        "        with open(self.f_test, 'w') as fp:\n",
        "            yaml.dump(test_results, fp)\n",
        "            \n",
        "        return test_results\n",
        "      \n",
        "        \n",
        "    def accuracy(self, predicts, targets):\n",
        "      \n",
        "        if 'class' in self.model_object: \n",
        "            _, predicts_indices = predicts.max(dim=1)\n",
        "            n_correct = torch.eq(predicts_indices, targets).sum().item()\n",
        "            return n_correct / len(predicts_indices) * 100\n",
        "\n",
        "        if self.model_object=='regression':\n",
        "            accu = torch.abs(predicts - targets).mean().item()\n",
        "            return accu\n",
        "          \n",
        "   \n",
        "    def html_loss_plot(self, image):\n",
        "        \n",
        "        h = HTML(\"<img src='{0}'/>\".format(image))\n",
        "    \n",
        "        return h\n",
        "\n",
        "    \n",
        "    def html_progress(self, var, value, max=100):\n",
        "      \n",
        "        h = HTML(\"\"\"{var}: <progress value='{value}' max='{max}', style='width: 80%'>{value}\n",
        "                           </progress>\"\"\".format(var=var, value=value, max=max))\n",
        "    \n",
        "        return h\n",
        "       \n",
        "      \n",
        "    def update_loss_plot(self):\n",
        "        \n",
        "        train_batch_loss = self.state['train_batch_loss']\n",
        "        train_batch_accu = self.state['train_batch_accu']\n",
        "        train_epoch_loss = self.state['train_epoch_loss']\n",
        "        train_epoch_accu = self.state['train_epoch_accu']\n",
        "\n",
        "        ntb = len(train_batch_loss)\n",
        "        nte = len(train_epoch_loss)\n",
        "        nnn = ntb/nte \n",
        "        xtb = np.arange(ntb)/nnn \n",
        "        xte = np.arange(nte, dtype=np.int16)\n",
        "\n",
        "        valid_batch_loss = self.state['valid_batch_loss']\n",
        "        valid_batch_accu = self.state['valid_batch_accu']\n",
        "        valid_epoch_loss = self.state['valid_epoch_loss']\n",
        "        valid_epoch_accu = self.state['valid_epoch_accu']\n",
        "\n",
        "        nvb = len(valid_batch_loss)\n",
        "        nve = len(valid_epoch_loss)\n",
        "        nnn = nvb/nve \n",
        "        xvb = np.arange(nvb)/nnn \n",
        "        xve = np.arange(nve, dtype=np.int16)\n",
        "\n",
        "        n = 2;  m = 2  # m features\n",
        "        if isinstance(self.col_target, list):\n",
        "            m = max(len(self.col_target), m)\n",
        "            n = 3\n",
        "        \n",
        "        fig, axes = plt.subplots(n, m, figsize=(12,8))\n",
        "        # loss\n",
        "        axes[0,0].plot(xtb, train_batch_loss)\n",
        "        axes[0,0].plot(xvb, valid_batch_loss)\n",
        "        axes[0,1].plot(xte, train_epoch_loss)        \n",
        "        axes[0,1].plot(xve, valid_epoch_loss)\n",
        "        # accuracy\n",
        "        if isinstance(self.col_target, list):  \n",
        "            for i in range(m): # feature\n",
        "                # train\n",
        "                #axes[1, i].plot(xtb, np.array(train_batch_accu)[:, i])\n",
        "                axes[1, i].plot(xte, np.array(train_epoch_accu)[:, i])\n",
        "                # validation\n",
        "                #axes[2, i].plot(xvb, np.array(valid_batch_accu)[:, i])\n",
        "                axes[2, i].plot(xve, np.array(valid_epoch_accu)[:, i])\n",
        "\n",
        "        else: # single feature prediction or classification\n",
        "            axes[1,0].plot(xtb, train_batch_accu)\n",
        "            axes[1,0].plot(xvb, valid_batch_accu)\n",
        "            axes[1,1].plot(xte, train_epoch_accu)\n",
        "            axes[1,1].plot(xve, valid_epoch_accu)\n",
        "\n",
        "        bio = io.BytesIO()\n",
        "        fig.savefig(bio, format='png')\n",
        "        bio.seek(0)\n",
        "        uri = 'data:image/png;base64,' + base64.encodebytes(bio.getvalue()).decode()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "        return uri\n",
        "      \n",
        "      \n",
        "    def update_save_state(self):\n",
        "        \n",
        "        # save state\n",
        "        with open(self.f_state, 'w') as fp: yaml.dump(self.state, fp)\n",
        "            \n",
        "        # save model\n",
        "        if self.state['epoch_index']==0:\n",
        "            if 'class' in self.model_object: self.state['best_accu'] = 0.\n",
        "            if self.model_object=='regression': self.state['best_accu'] = 999.\n",
        "            self.state['best_epoch'] = self.state['epoch_index']\n",
        "\n",
        "        cur_accu = self.state['valid_epoch_accu'][-1]\n",
        "        \n",
        "        is_improve = True\n",
        "        # classification accuray measures classification rate, increases \n",
        "        if 'class' in self.model_object and self.state['best_accu']>cur_accu: is_improve = False\n",
        "        # regresion accuracy measures the abs error difference, decreases\n",
        "        if self.model_object=='regression' and self.state['best_accu']<cur_accu: is_improve = False\n",
        "\n",
        "        if is_improve:\n",
        "            self.state['best_accu'] = cur_accu\n",
        "            self.state['best_epoch'] = self.state['epoch_index']\n",
        "            # save the model\n",
        "            state_cp = deepcopy(self.state)\n",
        "            state_cp['model_state_dict'] = self.model.state_dict()\n",
        "            state_cp['optim_state_dict'] = self.optimizer.state_dict()\n",
        "            torch.save(state_cp, self.f_model)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsPcSZqn_jax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Storm Inference Class\n",
        "\n",
        "Once the model is trained and optimized, this class will initiate the model based on the configuration file and the pytorch state dictionary file. The model is then used to make prediction on new samples, which is straightforward."
      ]
    },
    {
      "metadata": {
        "id": "Tdy9De-G_j8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ImageInference(object):\n",
        "  \n",
        "    def __init__(self, config, model_name):\n",
        "        # CUDA for PyTorch\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda:0' if self.use_cuda else 'cpu')\n",
        " \n",
        "        # Model\n",
        "        model = YML2ModelNet(config, model_name)\n",
        "        model_state = torch.load(config['params']['f_model_pth'])\n",
        "        model.load_state_dict(model_state['model_state_dict'])\n",
        "        self.model = model.to(self.device)\n",
        "        \n",
        "    def inference(self, imgs, apply_softmax=False):\n",
        "                      \n",
        "        self.model.eval() \n",
        "        with torch.no_grad():\n",
        "            imgs = imgs.to(self.device)  \n",
        "            predicts = self.model(imgs)\n",
        "            if apply_softmax: predicts = F.softmax(predicts, 1)\n",
        "        \n",
        "        return predicts.cpu().detach().numpy() \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}